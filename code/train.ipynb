{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#导入所需的包\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import os, sys\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score \n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Conv1D, MaxPooling1D,Input,Activation,Add\n",
    "from keras.layers import Flatten,Dense,LSTM,Bidirectional,GlobalAveragePooling1D,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session(gpu_fraction=0.1):\n",
    "    gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "    return tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "tf.compat.v1.keras.backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65411, 201, 1)\n",
      "(19244, 201, 1)\n",
      "(22671, 201, 1)\n"
     ]
    }
   ],
   "source": [
    "fn = \"data_intra.pk\"\n",
    "with open(fn, \"rb\") as fp:\n",
    "    X_train = pk.load(fp)\n",
    "    Y_train = pk.load(fp)\n",
    "    X_valid = pk.load(fp)\n",
    "    Y_valid = pk.load(fp)\n",
    "    X_test = pk.load(fp)\n",
    "    Y_test = pk.load(fp)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv_BN(input_name,num_filter,kernel_size):\n",
    "#     x = Conv1D(18, 7)(input_name)\n",
    "    x = Conv1D(num_filter,kernel_size,padding='same')(input_name)\n",
    "    x1 = BatchNormalization()(x)\n",
    "    return Activation('relu')(x1)\n",
    "\n",
    "def Conv_Res(input_name,num_filter,kernel_size):\n",
    "    x = Conv_BN(input_name,num_filter,kernel_size)\n",
    "    x1 = Conv_BN(x,num_filter,kernel_size)\n",
    "    return Add()([input_name,x1])\n",
    "\n",
    "def Conv_R_A(input_name,num_filter,kernel_size):\n",
    "    x = Conv_BN(input_name,num_filter,kernel_size)\n",
    "    x1 = Conv_BN(x,num_filter,kernel_size)\n",
    "    return Add()([input_name,x1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_m(f_size):\n",
    "    input1 = Input(shape=(f_size,1))\n",
    "    conv1 = Conv_BN(input1,16,32)\n",
    "\n",
    "    conv_r1 = Conv_Res(conv1,16,32)\n",
    "    conv2  = Conv1D(32,32,strides=2,padding='same')(conv_r1)\n",
    "    conv2_x = BatchNormalization()(conv2)\n",
    "    conv2_y = Activation('relu')(conv2_x)\n",
    "    conv_r2 = Conv_Res(conv2_y,32,32)\n",
    "    conv_r3 = Conv_Res(conv_r2,32,32)\n",
    "\n",
    "    conv3  = Conv1D(64,32,strides=2,padding='same')(conv_r3)\n",
    "    conv3_x = BatchNormalization()(conv3)\n",
    "    conv3_y = Activation('relu')(conv3_x)\n",
    "    conv_r4 = Conv_Res(conv3_y,64,32)\n",
    "\n",
    "    bl = Bidirectional(LSTM(units=40,return_sequences=True))(conv_r4)\n",
    "    gap1 = GlobalAveragePooling1D()(bl)\n",
    "\n",
    "    drop = Dropout(0.5)(gap1)\n",
    "    \n",
    "    fc1 = Dense(100, activation='relu')(drop)\n",
    "    fc2 = Dense(5, activation='softmax')(fc1)\n",
    "    model1 = Model(input1,fc2)\n",
    "    model1.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 201, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 201, 16)      528         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 201, 16)      64          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 201, 16)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 201, 16)      8208        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 201, 16)      64          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 201, 16)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 201, 16)      8208        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 201, 16)      64          conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 201, 16)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 201, 16)      0           activation_1[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 101, 32)      16416       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 101, 32)      128         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 101, 32)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 101, 32)      32800       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 101, 32)      128         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 101, 32)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 101, 32)      32800       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 101, 32)      128         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 101, 32)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 101, 32)      0           activation_4[0][0]               \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 101, 32)      32800       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 101, 32)      128         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 101, 32)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 101, 32)      32800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 101, 32)      128         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 101, 32)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 101, 32)      0           add_2[0][0]                      \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 51, 64)       65600       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 51, 64)       256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 51, 64)       0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 51, 64)       131136      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 51, 64)       256         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 51, 64)       0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 51, 64)       131136      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 51, 64)       256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 51, 64)       0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 51, 64)       0           activation_9[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 51, 80)       33600       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 80)           0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 80)           0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          8100        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5)            505         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 536,237\n",
      "Trainable params: 535,437\n",
      "Non-trainable params: 800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "f_size = X_train.shape[1]\n",
    "class_num = 5\n",
    "\n",
    "#============================================#\n",
    "\n",
    "lr = 0.01\n",
    "batch_size=32\n",
    "\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=class_num)\n",
    "\n",
    "\n",
    "model = make_m(f_size)\n",
    "\n",
    "best_SE = 0\n",
    "best_ACC = 0\n",
    "best_model = make_m(f_size)\n",
    "patience = 10\n",
    "pcnt = 0\n",
    "\n",
    "bin_label = lambda x: min(1,x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | SE: 0.7307 | Best SE: 0.7307 | ACC: 0.7934 | Best ACC: 0.7934 | AUC: 0.7779 | SP: 0.8251\n",
      "Epoch: 2 | SE: 0.7088 | Best SE: 0.7088 | ACC: 0.8330 | Best ACC: 0.8330 | AUC: 0.7884 | SP: 0.8681\n",
      "Epoch: 3 | SE: 0.8868 | Best SE: 0.7088 | ACC: 0.5129 | Best ACC: 0.8330 | AUC: 0.7045 | SP: 0.5221\n",
      "Epoch: 4 | SE: 0.3030 | Best SE: 0.7088 | ACC: 0.6321 | Best ACC: 0.8330 | AUC: 0.5132 | SP: 0.7233\n",
      "Epoch: 5 | SE: 0.7514 | Best SE: 0.7514 | ACC: 0.8191 | Best ACC: 0.8191 | AUC: 0.8035 | SP: 0.8557\n",
      "Epoch: 6 | SE: 0.6740 | Best SE: 0.7514 | ACC: 0.6630 | Best ACC: 0.8191 | AUC: 0.6751 | SP: 0.6762\n",
      "Epoch: 7 | SE: 0.6490 | Best SE: 0.7514 | ACC: 0.8630 | Best ACC: 0.8191 | AUC: 0.7799 | SP: 0.9109\n",
      "Epoch: 8 | SE: 0.7845 | Best SE: 0.7514 | ACC: 0.6718 | Best ACC: 0.8191 | AUC: 0.7336 | SP: 0.6828\n",
      "Epoch: 9 | SE: 0.8368 | Best SE: 0.8368 | ACC: 0.7491 | Best ACC: 0.7491 | AUC: 0.7981 | SP: 0.7593\n",
      "Epoch: 10 | SE: 0.7557 | Best SE: 0.7557 | ACC: 0.8715 | Best ACC: 0.8715 | AUC: 0.8323 | SP: 0.9088\n",
      "Epoch: 11 | SE: 0.7983 | Best SE: 0.7983 | ACC: 0.8309 | Best ACC: 0.8309 | AUC: 0.8270 | SP: 0.8556\n",
      "Epoch: 12 | SE: 0.3490 | Best SE: 0.7983 | ACC: 0.5382 | Best ACC: 0.8309 | AUC: 0.4741 | SP: 0.5992\n",
      "Epoch: 13 | SE: 0.7872 | Best SE: 0.7872 | ACC: 0.8658 | Best ACC: 0.8658 | AUC: 0.8440 | SP: 0.9008\n",
      "Epoch: 14 | SE: 0.6767 | Best SE: 0.7872 | ACC: 0.7959 | Best ACC: 0.8658 | AUC: 0.7526 | SP: 0.8285\n",
      "Epoch: 15 | SE: 0.7297 | Best SE: 0.7872 | ACC: 0.8249 | Best ACC: 0.8658 | AUC: 0.7932 | SP: 0.8566\n",
      "Epoch: 16 | SE: 0.4456 | Best SE: 0.7872 | ACC: 0.8189 | Best ACC: 0.8658 | AUC: 0.6757 | SP: 0.9059\n",
      "Epoch: 17 | SE: 0.8000 | Best SE: 0.7872 | ACC: 0.5035 | Best ACC: 0.8658 | AUC: 0.6335 | SP: 0.4670\n",
      "Epoch: 18 | SE: 0.5774 | Best SE: 0.7872 | ACC: 0.8151 | Best ACC: 0.8658 | AUC: 0.7229 | SP: 0.8685\n",
      "Epoch: 19 | SE: 0.5530 | Best SE: 0.7872 | ACC: 0.7582 | Best ACC: 0.8658 | AUC: 0.6830 | SP: 0.8129\n",
      "Epoch: 20 | SE: 0.4041 | Best SE: 0.7872 | ACC: 0.7366 | Best ACC: 0.8658 | AUC: 0.6158 | SP: 0.8276\n",
      "Epoch: 21 | SE: 0.6966 | Best SE: 0.7872 | ACC: 0.7941 | Best ACC: 0.8658 | AUC: 0.7622 | SP: 0.8278\n",
      "Epoch: 22 | SE: 0.8098 | Best SE: 0.7872 | ACC: 0.8431 | Best ACC: 0.8658 | AUC: 0.8406 | SP: 0.8713\n",
      "Epoch: 23 | SE: 0.8091 | Best SE: 0.8091 | ACC: 0.8485 | Best ACC: 0.8485 | AUC: 0.8411 | SP: 0.8730\n",
      "Epoch: 24 | SE: 0.8328 | Best SE: 0.8091 | ACC: 0.7986 | Best ACC: 0.8485 | AUC: 0.8261 | SP: 0.8193\n",
      "Epoch: 25 | SE: 0.3331 | Best SE: 0.8091 | ACC: 0.7585 | Best ACC: 0.8485 | AUC: 0.5969 | SP: 0.8608\n",
      "Epoch: 26 | SE: 0.7436 | Best SE: 0.8091 | ACC: 0.7583 | Best ACC: 0.8485 | AUC: 0.7739 | SP: 0.8042\n",
      "Epoch: 27 | SE: 0.7953 | Best SE: 0.8091 | ACC: 0.7921 | Best ACC: 0.8485 | AUC: 0.8054 | SP: 0.8155\n",
      "Epoch: 28 | SE: 0.7956 | Best SE: 0.8091 | ACC: 0.8535 | Best ACC: 0.8485 | AUC: 0.8392 | SP: 0.8828\n",
      "Epoch: 29 | SE: 0.7625 | Best SE: 0.8091 | ACC: 0.8342 | Best ACC: 0.8485 | AUC: 0.8156 | SP: 0.8687\n",
      "Epoch: 30 | SE: 0.7659 | Best SE: 0.8091 | ACC: 0.8706 | Best ACC: 0.8485 | AUC: 0.8332 | SP: 0.9006\n",
      "Epoch: 31 | SE: 0.7966 | Best SE: 0.8091 | ACC: 0.8149 | Best ACC: 0.8485 | AUC: 0.8175 | SP: 0.8384\n",
      "Epoch: 32 | SE: 0.8199 | Best SE: 0.8091 | ACC: 0.7021 | Best ACC: 0.8485 | AUC: 0.7650 | SP: 0.7100\n",
      "Epoch: 33 | SE: 0.6389 | Best SE: 0.8091 | ACC: 0.8573 | Best ACC: 0.8485 | AUC: 0.7735 | SP: 0.9081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingang/anaconda3/envs/lzy/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.95      0.82      0.88     19629\n",
      "           S       0.17      0.03      0.04       505\n",
      "           V       0.35      0.94      0.51      2139\n",
      "           F       0.00      0.00      0.00       392\n",
      "           Q       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.80     22671\n",
      "   macro avg       0.29      0.36      0.29     22671\n",
      "weighted avg       0.86      0.80      0.81     22671\n",
      "\n",
      "Epoch: 34 | SE: 0.7358 | Best SE: 0.8091 | ACC: 0.7358 | Best ACC: 0.8485 | AUC: 0.7422 | SP: 0.7486\n",
      "Epoch: 35 | SE: 0.7730 | Best SE: 0.8091 | ACC: 0.8510 | Best ACC: 0.8485 | AUC: 0.8262 | SP: 0.8795\n",
      "Epoch: 36 | SE: 0.7973 | Best SE: 0.7973 | ACC: 0.8780 | Best ACC: 0.8780 | AUC: 0.8540 | SP: 0.9107\n",
      "Epoch: 37 | SE: 0.5527 | Best SE: 0.7973 | ACC: 0.6591 | Best ACC: 0.8780 | AUC: 0.6245 | SP: 0.6962\n",
      "Epoch: 38 | SE: 0.7709 | Best SE: 0.7973 | ACC: 0.8554 | Best ACC: 0.8780 | AUC: 0.8280 | SP: 0.8850\n",
      "Epoch: 39 | SE: 0.7311 | Best SE: 0.7973 | ACC: 0.8531 | Best ACC: 0.8780 | AUC: 0.8129 | SP: 0.8947\n",
      "Epoch: 40 | SE: 0.7875 | Best SE: 0.7973 | ACC: 0.8374 | Best ACC: 0.8780 | AUC: 0.8276 | SP: 0.8677\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for e in range(1, 40+1):\n",
    "\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, epochs=1, verbose=0)\n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    acc = np.sum(y_pred==Y_valid)/len(Y_valid)\n",
    "\n",
    "    y_true = list(map(bin_label, Y_valid))\n",
    "    y_pred = list(map(bin_label, y_pred))\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    SE = tp/(tp+fn)\n",
    "    SP = tn/(fp+tn)\n",
    "\n",
    "    if SE+acc > best_SE+best_ACC:\n",
    "        best_SE, best_ACC = SE, acc\n",
    "        best_model.set_weights(model.get_weights())\n",
    "        pcnt = 0\n",
    "    else:\n",
    "        pcnt += 1\n",
    "    \n",
    "    print(\"Epoch: %d | SE: %.4f | Best SE: %.4f | ACC: %.4f | Best ACC: %.4f | AUC: %.4f | SP: %.4f\" %(e, SE, best_SE, acc, best_ACC, auc, SP))\n",
    "\n",
    "    if pcnt==patience:\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        acc = np.sum(y_pred==Y_test)/len(Y_test)\n",
    "#         y_true = list(map(bin_label, Y_test))\n",
    "#         y_pred = list(map(bin_label, y_pred))\n",
    "#         auc = roc_auc_score(y_true, y_pred)\n",
    "#         tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "#         SE = tp/(tp+fn)\n",
    "#         SP = tn/(fp+tn)\n",
    "        print(metrics.classification_report(Y_test, y_pred, target_names=['N','S','V','F','Q']))\n",
    "#         print(\" Test | SE: %.4f | ACC: %.4f | AUC: %.4f | SP: %.4f | valid SE: %.4f | valid ACC: %.4f\" %(SE, acc, auc, SP, best_SE, best_ACC))\n",
    "#         with open(\"./result/\"+save, \"a\") as fw:\n",
    "#             fw.write(\"SE: %.4f | ACC: %.4f | AUC: %.4f | SP: %.4f | valid SE: %.4f | valid ACC: %.4f\\n\" %(SE, acc, auc, SP, best_SE, best_ACC))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | SE: 0.7375 | Best SE: 0.7375 | ACC: 0.7567 | Best ACC: 0.7567 | AUC: 0.7614 | SP: 0.7853\n",
      "Epoch: 2 | SE: 0.7872 | Best SE: 0.7872 | ACC: 0.7915 | Best ACC: 0.7915 | AUC: 0.8125 | SP: 0.8378\n",
      "Epoch: 3 | SE: 0.3017 | Best SE: 0.7872 | ACC: 0.7085 | Best ACC: 0.7915 | AUC: 0.5504 | SP: 0.7991\n",
      "Epoch: 4 | SE: 0.7530 | Best SE: 0.7872 | ACC: 0.8080 | Best ACC: 0.7915 | AUC: 0.7969 | SP: 0.8408\n",
      "Epoch: 5 | SE: 0.7561 | Best SE: 0.7872 | ACC: 0.7512 | Best ACC: 0.7915 | AUC: 0.7654 | SP: 0.7746\n",
      "Epoch: 6 | SE: 0.7409 | Best SE: 0.7872 | ACC: 0.8131 | Best ACC: 0.7915 | AUC: 0.7946 | SP: 0.8483\n",
      "Epoch: 7 | SE: 0.8274 | Best SE: 0.8274 | ACC: 0.7946 | Best ACC: 0.7946 | AUC: 0.8164 | SP: 0.8055\n",
      "Epoch: 8 | SE: 0.7000 | Best SE: 0.8274 | ACC: 0.7827 | Best ACC: 0.7946 | AUC: 0.7597 | SP: 0.8193\n",
      "Epoch: 9 | SE: 0.7291 | Best SE: 0.8274 | ACC: 0.7721 | Best ACC: 0.7946 | AUC: 0.7629 | SP: 0.7968\n",
      "Epoch: 10 | SE: 0.7088 | Best SE: 0.8274 | ACC: 0.7938 | Best ACC: 0.7946 | AUC: 0.7670 | SP: 0.8252\n",
      "Epoch: 11 | SE: 0.7351 | Best SE: 0.8274 | ACC: 0.7307 | Best ACC: 0.7946 | AUC: 0.7432 | SP: 0.7513\n",
      "Epoch: 12 | SE: 0.6757 | Best SE: 0.8274 | ACC: 0.8204 | Best ACC: 0.7946 | AUC: 0.7684 | SP: 0.8612\n",
      "Epoch: 13 | SE: 0.8206 | Best SE: 0.8274 | ACC: 0.7872 | Best ACC: 0.7946 | AUC: 0.8098 | SP: 0.7990\n",
      "Epoch: 14 | SE: 0.7885 | Best SE: 0.8274 | ACC: 0.7618 | Best ACC: 0.7946 | AUC: 0.7822 | SP: 0.7758\n",
      "Epoch: 15 | SE: 0.7699 | Best SE: 0.8274 | ACC: 0.7493 | Best ACC: 0.7946 | AUC: 0.7646 | SP: 0.7593\n",
      "Epoch: 16 | SE: 0.3355 | Best SE: 0.8274 | ACC: 0.6507 | Best ACC: 0.7946 | AUC: 0.5292 | SP: 0.7230\n",
      "Epoch: 17 | SE: 0.3507 | Best SE: 0.8274 | ACC: 0.7067 | Best ACC: 0.7946 | AUC: 0.5703 | SP: 0.7899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.94      0.79      0.86     19629\n",
      "           S       0.18      0.01      0.02       505\n",
      "           V       0.28      0.76      0.41      2139\n",
      "           F       0.17      0.00      0.01       392\n",
      "           Q       0.00      0.17      0.01         6\n",
      "\n",
      "    accuracy                           0.76     22671\n",
      "   macro avg       0.31      0.34      0.26     22671\n",
      "weighted avg       0.85      0.76      0.78     22671\n",
      "\n",
      "Epoch: 18 | SE: 0.7628 | Best SE: 0.8274 | ACC: 0.7178 | Best ACC: 0.7946 | AUC: 0.7451 | SP: 0.7274\n",
      "Epoch: 19 | SE: 0.6459 | Best SE: 0.8274 | ACC: 0.6795 | Best ACC: 0.7946 | AUC: 0.6958 | SP: 0.7456\n",
      "Epoch: 20 | SE: 0.7639 | Best SE: 0.8274 | ACC: 0.7889 | Best ACC: 0.7946 | AUC: 0.7895 | SP: 0.8152\n",
      "Epoch: 21 | SE: 0.4243 | Best SE: 0.8274 | ACC: 0.6527 | Best ACC: 0.7946 | AUC: 0.5673 | SP: 0.7103\n",
      "Epoch: 22 | SE: 0.7983 | Best SE: 0.8274 | ACC: 0.7839 | Best ACC: 0.7946 | AUC: 0.7988 | SP: 0.7993\n",
      "Epoch: 23 | SE: 0.7578 | Best SE: 0.8274 | ACC: 0.7706 | Best ACC: 0.7946 | AUC: 0.7734 | SP: 0.7891\n",
      "Epoch: 24 | SE: 0.4071 | Best SE: 0.8274 | ACC: 0.7129 | Best ACC: 0.7946 | AUC: 0.5949 | SP: 0.7828\n",
      "Epoch: 25 | SE: 0.5892 | Best SE: 0.8274 | ACC: 0.7291 | Best ACC: 0.7946 | AUC: 0.6800 | SP: 0.7709\n",
      "Epoch: 26 | SE: 0.6297 | Best SE: 0.8274 | ACC: 0.6987 | Best ACC: 0.7946 | AUC: 0.6800 | SP: 0.7302\n",
      "Epoch: 27 | SE: 0.6639 | Best SE: 0.8274 | ACC: 0.7491 | Best ACC: 0.7946 | AUC: 0.7214 | SP: 0.7789\n",
      "Epoch: 28 | SE: 0.8101 | Best SE: 0.8274 | ACC: 0.8058 | Best ACC: 0.7946 | AUC: 0.8145 | SP: 0.8190\n",
      "Epoch: 29 | SE: 0.4351 | Best SE: 0.8274 | ACC: 0.6996 | Best ACC: 0.7946 | AUC: 0.6004 | SP: 0.7657\n",
      "Epoch: 30 | SE: 0.6841 | Best SE: 0.8274 | ACC: 0.7338 | Best ACC: 0.7946 | AUC: 0.7234 | SP: 0.7628\n",
      "Epoch: 31 | SE: 0.7970 | Best SE: 0.8274 | ACC: 0.6793 | Best ACC: 0.7946 | AUC: 0.7371 | SP: 0.6772\n",
      "Epoch: 32 | SE: 0.7834 | Best SE: 0.8274 | ACC: 0.7520 | Best ACC: 0.7946 | AUC: 0.7741 | SP: 0.7647\n",
      "Epoch: 33 | SE: 0.4787 | Best SE: 0.8274 | ACC: 0.6770 | Best ACC: 0.7946 | AUC: 0.6025 | SP: 0.7264\n",
      "Epoch: 34 | SE: 0.7828 | Best SE: 0.8274 | ACC: 0.6980 | Best ACC: 0.7946 | AUC: 0.7418 | SP: 0.7009\n",
      "Epoch: 35 | SE: 0.5020 | Best SE: 0.8274 | ACC: 0.6791 | Best ACC: 0.7946 | AUC: 0.6155 | SP: 0.7290\n",
      "Epoch: 36 | SE: 0.7297 | Best SE: 0.8274 | ACC: 0.6958 | Best ACC: 0.7946 | AUC: 0.7259 | SP: 0.7221\n",
      "Epoch: 37 | SE: 0.7875 | Best SE: 0.8274 | ACC: 0.7595 | Best ACC: 0.7946 | AUC: 0.7803 | SP: 0.7732\n",
      "Epoch: 38 | SE: 0.6193 | Best SE: 0.8274 | ACC: 0.7164 | Best ACC: 0.7946 | AUC: 0.6824 | SP: 0.7455\n",
      "Epoch: 39 | SE: 0.5280 | Best SE: 0.8274 | ACC: 0.7046 | Best ACC: 0.7946 | AUC: 0.6398 | SP: 0.7516\n",
      "Epoch: 40 | SE: 0.8247 | Best SE: 0.8274 | ACC: 0.6612 | Best ACC: 0.7946 | AUC: 0.7368 | SP: 0.6490\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f_size = X_train.shape[1]\n",
    "class_num = 5\n",
    "\n",
    "#============================================#\n",
    "\n",
    "lr = 0.01\n",
    "batch_size=32\n",
    "\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes=class_num)\n",
    "\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(18, 7, activation='relu', input_shape=(f_size,1)))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(18, 7, activation='relu'))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(class_num, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr))\n",
    "    return model\n",
    "model = make_model()\n",
    "\n",
    "best_SE = 0\n",
    "best_ACC = 0\n",
    "best_model = make_model()\n",
    "patience = 10\n",
    "pcnt = 0\n",
    "\n",
    "bin_label = lambda x: min(1,x)\n",
    "\n",
    "for e in range(1, 40+1):\n",
    "\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, epochs=1, verbose=0)\n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    acc = np.sum(y_pred==Y_valid)/len(Y_valid)\n",
    "\n",
    "    y_true = list(map(bin_label, Y_valid))\n",
    "    y_pred = list(map(bin_label, y_pred))\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    SE = tp/(tp+fn)\n",
    "    SP = tn/(fp+tn)\n",
    "\n",
    "    if SE+acc > best_SE+best_ACC:\n",
    "        best_SE, best_ACC = SE, acc\n",
    "        best_model.set_weights(model.get_weights())\n",
    "        pcnt = 0\n",
    "    else:\n",
    "        pcnt += 1\n",
    "    \n",
    "    print(\"Epoch: %d | SE: %.4f | Best SE: %.4f | ACC: %.4f | Best ACC: %.4f | AUC: %.4f | SP: %.4f\" %(e, SE, best_SE, acc, best_ACC, auc, SP))\n",
    "\n",
    "    if pcnt==patience:\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        acc = np.sum(y_pred==Y_test)/len(Y_test)\n",
    "#         y_true = list(map(bin_label, Y_test))\n",
    "#         y_pred = list(map(bin_label, y_pred))\n",
    "#         auc = roc_auc_score(y_true, y_pred)\n",
    "#         tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "#         SE = tp/(tp+fn)\n",
    "#         SP = tn/(fp+tn)\n",
    "        print(metrics.classification_report(Y_test, y_pred, target_names=['N','S','V','F','Q']))\n",
    "#         print(\" Test | SE: %.4f | ACC: %.4f | AUC: %.4f | SP: %.4f | valid SE: %.4f | valid ACC: %.4f\" %(SE, acc, auc, SP, best_SE, best_ACC))\n",
    "#         with open(\"./result/\"+save, \"a\") as fw:\n",
    "#             fw.write(\"SE: %.4f | ACC: %.4f | AUC: %.4f | SP: %.4f | valid SE: %.4f | valid ACC: %.4f\\n\" %(SE, acc, auc, SP, best_SE, best_ACC))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.94      0.77      0.85     19629\n",
      "           S       0.34      0.17      0.23       505\n",
      "           V       0.29      0.84      0.43      2139\n",
      "           F       0.00      0.00      0.00       392\n",
      "           Q       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.75     22671\n",
      "   macro avg       0.31      0.36      0.30     22671\n",
      "weighted avg       0.85      0.75      0.78     22671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(metrics.classification_report(Y_test, y_pred, target_names=['N','S','V','F','Q']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test | SE: 0.9505 | ACC: 0.9848 | AUC: 0.9723 | SP: 0.9940 | valid SE: 0.9542 | valid ACC: 0.9849\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "acc = np.sum(y_pred==Y_test)/len(Y_test)\n",
    "y_true = list(map(bin_label, Y_test))\n",
    "y_pred = list(map(bin_label, y_pred))\n",
    "auc = roc_auc_score(y_true, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "SE = tp/(tp+fn)\n",
    "SP = tn/(fp+tn)\n",
    "print(\" Test | SE: %.4f | ACC: %.4f | AUC: %.4f | SP: %.4f | valid SE: %.4f | valid ACC: %.4f\" %(SE, acc, auc, SP, best_SE, best_ACC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.99      0.99      0.99     18113\n",
      "           S       0.83      0.78      0.80       517\n",
      "           V       0.98      0.96      0.97      1470\n",
      "           F       0.87      0.82      0.85       161\n",
      "           Q       0.99      0.99      0.99      1632\n",
      "\n",
      "    accuracy                           0.98     21893\n",
      "   macro avg       0.93      0.91      0.92     21893\n",
      "weighted avg       0.98      0.98      0.98     21893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(metrics.classification_report(Y_test, y_pred, target_names=['N','S','V','F','Q']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
